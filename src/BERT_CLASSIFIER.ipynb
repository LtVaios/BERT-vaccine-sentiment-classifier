{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ai_hw4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Nessecary installations and imports."
      ],
      "metadata": {
        "id": "YWtjETI8wJuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==3\n",
        "\n",
        "import torch\n",
        "from transformers import BertTokenizer\n",
        "from transformers import AutoModel\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import *\n",
        "import torch.nn as nn\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize,RegexpTokenizer\n",
        "\n",
        "#nltk stopwords and punctuation datasets download\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "9_IukY0VmrbB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3511036-a5d6-458c-a0d8-919bf01b191f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==3 in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.0.47)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (4.62.3)\n",
            "Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.8.0rc4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3) (3.4.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.1.96)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3) (1.21.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3) (3.0.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.15.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the datasets and cleaning them in the same way I did for the previous 2 projects."
      ],
      "metadata": {
        "id": "2_MqU-1GwOdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset and variables initialization\n",
        "fields = ['tweet', 'label']\n",
        "trainset = pd.read_csv(\"/content/data/vaccine_train_set.csv\", usecols=fields)\n",
        "testset = pd.read_csv(\"/content/data/vaccine_validation_set.csv\", usecols=fields)\n",
        "X_train = []\n",
        "Y_train = []\n",
        "X_train = trainset.tweet\n",
        "Y_train = trainset.label\n",
        "X_test = []\n",
        "Y_test = []\n",
        "X_test = testset.tweet\n",
        "Y_test = testset.label\n",
        "\n",
        "#data cleaning\n",
        "def clean_data(dataset):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    #adding symbols we dont need in the stop words because the tokenizer tokenizes them alone anyway\n",
        "    stop_words.add(\":\")\n",
        "    stop_words.add(\"@\")\n",
        "    stop_words.add(\"#\")\n",
        "    stop_words.add(\",\")\n",
        "    stop_words.add(\".\")\n",
        "    stop_words.add(\"\\'\\'\")\n",
        "    new_dataset = []\n",
        "    for row in dataset:\n",
        "      dataset_tokens = word_tokenize(row)\n",
        "      filtered = \"\"\n",
        "      for w in dataset_tokens:\n",
        "        #filtering stop_words and weird symbols (see above), removing the http word and removing links\n",
        "        if (w not in stop_words) and (\"http\" not in w) and (\"/\" not in w ):\n",
        "          filtered = filtered + \" \" + w\n",
        "      new_dataset.append(filtered)\n",
        "    return new_dataset\n",
        "X_train = clean_data(X_train)\n",
        "X_test = clean_data(X_test)\n",
        "x = X_train\n",
        "y= Y_train\n",
        "\n",
        "\n",
        "pretrained_bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "RygbGrlJ6ICx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the datasets into tokens and encoding them to be ready for feed in our BERT model later. We also wrap the input with the labels and the masks together so they dont get shuffled when we split the batches later."
      ],
      "metadata": {
        "id": "aE6xVWsOv6xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = 25\n",
        "\n",
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    x,\n",
        "    max_length = seq_len,\n",
        "    pad_to_max_length = True,\n",
        "    truncation = True\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    X_test,\n",
        "    max_length = seq_len,\n",
        "    pad_to_max_length = True,\n",
        "    truncation = True\n",
        ")\n",
        "\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_y = torch.tensor(y.tolist())\n",
        "dataset = torch.utils.data.TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_y = torch.tensor(Y_test.tolist())"
      ],
      "metadata": {
        "id": "02gC1C-Cal9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first function is used to calculate the model's scores and print as a whole and for each class individually using the scikit learn metric functions. The second function calculates the f1 score, loss and returns it so it can be used later to measure which epoch had the best fine-tuning for our model."
      ],
      "metadata": {
        "id": "UCV-cd15viT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_scores(ts, mask, y_testset, my_model,LossFunc):\n",
        "  #we do the same as in training but in the test dataset so we test our model in the end\n",
        "  with torch.no_grad():\n",
        "    my_model.eval()\n",
        "    x = ts.to(device)\n",
        "    mask = mask.to(device)\n",
        "    y_testset = y_testset.to(device)\n",
        "\n",
        "    #predictions\n",
        "    y_pred_t = my_model(x, mask)\n",
        "    y_final = []\n",
        "\n",
        "    #take the max of the 3 outputs and append y_final with the correct label (0,1,2) \n",
        "    #which will be compared with the real labels to calculate score\n",
        "    for i in range(len(y_pred_t)):\n",
        "      if(max(y_pred_t[i]) == y_pred_t[i][0]):\n",
        "        y_final.append(0)\n",
        "      elif(max(y_pred_t[i]) == y_pred_t[i][1]):\n",
        "        y_final.append(1)\n",
        "      else:\n",
        "        y_final.append(2)\n",
        "\n",
        "    y_testset = y_testset.cpu()\n",
        "    #calculate whole scores\n",
        "    confm=confusion_matrix(y_testset, y_final)\n",
        "    score = ((int)(confm[0][0] + confm[1][1] +confm[2][2])/len(y_testset))\n",
        "    print(\"Testset accuracy score: \", score)\n",
        "\n",
        "    f1 = f1_score(y_testset, y_final, average='weighted')\n",
        "    print(\"Testset f1 score: \", score)\n",
        "\n",
        "    rec = recall_score(y_testset, y_final, average='weighted')\n",
        "    print(\"Testset recall score: \", score)\n",
        "\n",
        "    prec = precision_score(y_testset, y_final, average='weighted',zero_division=0)\n",
        "    print(\"Testset accuracy score: \", score)\n",
        "\n",
        "    #calculate individual scores\n",
        "    print(\"-----------------------------------------------------\")\n",
        "    zero, one, two = f1_score(y_testset, y_final,average=None)\n",
        "    print(\"Label 0 f1 score: \", zero)\n",
        "    print(\"Label 1 f1 score: \", one)\n",
        "    print(\"Label 2 f1 score: \", two)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    zero, one, two = recall_score(y_testset, y_final, average=None)\n",
        "    print(\"Label 0 recall score: \", zero)\n",
        "    print(\"Label 1 recall score: \", one)\n",
        "    print(\"Label 2 recall score: \", two)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    zero, one, two = precision_score(y_testset, y_final, average=None,zero_division=0)\n",
        "    print(\"Label 0 precision score: \", zero)\n",
        "    print(\"Label 1 precision score: \", one)\n",
        "    print(\"Label 2 precision score: \", two)\n",
        "    return\n",
        "\n",
        "#This function is made to calculate the loss and score of the model in the testset so it prints that info in each epoch to watch the progress\n",
        "def calc_loss_and_score(data, mask, labels, my_model,LossFunc):\n",
        "    with torch.no_grad():\n",
        "      my_model.eval()\n",
        "      data = data.to(device)\n",
        "      mask = mask.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      \n",
        "      # Get predictions and calculate loss\n",
        "      output = my_model(data, mask)\n",
        "\n",
        "      y_final = []\n",
        "\n",
        "      for i in range(len(output)):\n",
        "        if(max(output[i]) == output[i][0]):\n",
        "          y_final.append(0)\n",
        "        elif(max(output[i]) == output[i][1]):\n",
        "          y_final.append(1)\n",
        "        else:\n",
        "          y_final.append(2)\n",
        "\n",
        "      loss = LossFunc(output, labels)\n",
        "\n",
        "      #calculate score\n",
        "      labels = labels.detach().cpu().numpy()\n",
        "      output = output.detach().cpu().numpy()\n",
        "      f1 = f1_score(y_final, labels, average='weighted')\n",
        "\n",
        "      return loss, f1"
      ],
      "metadata": {
        "id": "EV2zubdOkj3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the bert model with all the suggested hyperparameter tuning suggested in the official BERT paper: https://aclanthology.org/N19-1423.pdf. Those are batch size: 32, LR: 5e-3, number of epochs: 3, CrossEntropyLoss, Adam optimizer, sequence length: 25. After experimenting I concluded that the best gradient cliping ratio is 4."
      ],
      "metadata": {
        "id": "1xAEsGq0uSdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyBERT(nn.Module):\n",
        "  \n",
        "    def __init__(self, BERT):\n",
        "      super(MyBERT, self).__init__()\n",
        "      self.BERT = BERT\n",
        "\n",
        "      #input layer\n",
        "      self.l1 = nn.Linear(768,383)\n",
        "      # output layer\n",
        "      self.l2 = nn.Linear(383,3)\n",
        "\n",
        "      #Activation function and softmax for the output\n",
        "      self.af = nn.PReLU()\n",
        "      self.softmax = nn.Softmax(dim=1)\n",
        "      \n",
        "\n",
        "    #forward pass\n",
        "    def forward(self, data, mask):\n",
        "      #pass the inputs to the model  \n",
        "      _ , input = self.BERT(data, attention_mask=mask)\n",
        "      x = self.l1(input)\n",
        "      x = self.af(x)\n",
        "      x = self.l2(x)\n",
        "      #x = self.softmax(x)\n",
        "\n",
        "      return x\n",
        "\n",
        "\n",
        "#--------------HYPERPARAMETERS---------------\n",
        "LR = 0.00005\n",
        "grad_clip = 4\n",
        "batch_sz = 32\n",
        "N_EPOCHS = 3\n",
        "#-------------------------------------------------\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "  print(\"cuda\")\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "  print(\"cpu\")\n",
        "\n",
        "# pass the pre-trained BERT to our define architecture\n",
        "model = MyBERT(pretrained_bert)\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "#Initialize dataloader\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_sz, shuffle=True)"
      ],
      "metadata": {
        "id": "JhkrKXeydWGh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd742ea1-486a-4959-8f7d-383a1c8c7c5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the fine-tuning cell. We unpack the batches in input and masks and we feed those to our model. Gradient cliping is used for the exploding gradients problem as we saw in RNNs. Finally, after each epoch if it had better stats than the previous epoch we save the model's current state to be used in testing."
      ],
      "metadata": {
        "id": "378V91r9teav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "min_loss = 999999\n",
        "torch.cuda.empty_cache()\n",
        "for epoch_i in range(N_EPOCHS):\n",
        "    # Ensure net in training mode\n",
        "    model.train()\n",
        "    batch_losses = []\n",
        "    for batch in dataloader:\n",
        "      batch = [row.to(device) for row in batch]\n",
        "      data , mask, y_batch = batch\n",
        "\n",
        "      # Get model output, calculate loss, and generate gradients\n",
        "      output = model(data, mask)\n",
        "\n",
        "      #Calculate loss\n",
        "      y_batch = y_batch.type(torch.LongTensor)\n",
        "      y_batch = y_batch.to(device)\n",
        "      loss = loss_func(output, y_batch)\n",
        "      batch_losses.append(loss.item())\n",
        "\n",
        "      # Zero out gradients\n",
        "      model.zero_grad()\n",
        "\n",
        "      # Generate gradients via autodiff\n",
        "      loss.backward() \n",
        "      \n",
        "      # Clip gradients like we did in RNN nets\n",
        "      for param in model.parameters():\n",
        "          if param.grad is None:\n",
        "              continue\n",
        "          grad_val = torch.clamp(param.grad, -grad_clip, grad_clip)\n",
        "\n",
        "      #update gradients\n",
        "      optimizer.step()\n",
        "\n",
        "      output=output.detach().cpu().numpy()\n",
        "\n",
        "      # Track loss\n",
        "      losses.append(loss.item())\n",
        "    \n",
        "    #Calculating score and loss in each epoch just to gather more info about the progress\n",
        "    temp_loss, temp_score = calc_loss_and_score(test_seq, test_mask, test_y, model, loss_func)\n",
        "\n",
        "    #If the current state of BERT is the best so far we save it in order to backroll to it later\n",
        "    if(temp_loss < min_loss):\n",
        "      min_loss = temp_loss\n",
        "      torch.save(model.state_dict(), 'min_loss')\n",
        "\n",
        "    str_ = f'\\rEpoch {epoch_i+1}/{N_EPOCHS} -- Train Loss: {sum(batch_losses)/len(dataloader):.5f} -- Testset f1 Score: {temp_score}'\n",
        "    print(str_)"
      ],
      "metadata": {
        "id": "390UwwMTjq-P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e3f8b94-6e11-438f-a4e4-6b7a0555d7f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 -- Train Loss: 0.20849 -- Testset f1 Score: 0.7351637851023628\n",
            "Epoch 2/3 -- Train Loss: 0.11687 -- Testset f1 Score: 0.731839630028322\n",
            "Epoch 3/3 -- Train Loss: 0.09165 -- Testset f1 Score: 0.7281005042385814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the best model from all the epochs and printing the scores. The first scores are the model's scores and beloq are the scores for each class individually."
      ],
      "metadata": {
        "id": "c5waycNxtLqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  #loading the best fine tuned model from the 3 training epochs\n",
        "  path = 'min_loss'\n",
        "  model.load_state_dict(torch.load(path))\n",
        "  print(\"BERT Model scores:\")\n",
        "  print_scores(test_seq, test_mask, test_y, model, loss_func)"
      ],
      "metadata": {
        "id": "jPHe1eJQ0xxX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f8ff9f4-bb7a-4d0b-825f-123498aa870b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT Model scores:\n",
            "Testset accuracy score:  0.7357581069237511\n",
            "Testset f1 score:  0.7357581069237511\n",
            "Testset recall score:  0.7357581069237511\n",
            "Testset accuracy score:  0.7357581069237511\n",
            "-----------------------------------------------------\n",
            "Label 0 f1 score:  0.7940038684719536\n",
            "Label 1 f1 score:  0.5426621160409556\n",
            "Label 2 f1 score:  0.7319371727748691\n",
            "\n",
            "\n",
            "Label 0 recall score:  0.7708920187793428\n",
            "Label 1 recall score:  0.5371621621621622\n",
            "Label 2 recall score:  0.758957654723127\n",
            "\n",
            "\n",
            "Label 0 precision score:  0.8185443668993021\n",
            "Label 1 precision score:  0.5482758620689655\n",
            "Label 2 precision score:  0.7067745197168858\n"
          ]
        }
      ]
    }
  ]
}